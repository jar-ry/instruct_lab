version: 3
domain: ai principles
task_description: "Australia's AI principles"
created_by: Jar-ry
seed_examples:
  - context: |
      Australia’s AI Ethics Principles at a glance
      Human, societal and environmental wellbeing: AI systems should benefit individuals, society and the environment.
      Human-centred values: AI systems should respect human rights, diversity, and the autonomy of individuals.
      Fairness: AI systems should be inclusive and accessible, and should not involve or result in unfair discrimination against individuals, communities or groups.
      Privacy protection and security: AI systems should respect and uphold privacy rights and data protection, and ensure the security of data.
      Reliability and safety: AI systems should reliably operate in accordance with their intended purpose.
      Transparency and explainability: There should be transparency and responsible disclosure so people can understand when they are being significantly impacted by AI, and can find out when an AI system is engaging with them.
      Contestability: When an AI system significantly impacts a person, community, group or environment, there should be a timely process to allow people to challenge the use or outcomes of the AI system.
      Accountability: People responsible for the different phases of the AI system lifecycle should be identifiable and accountable for the outcomes of the AI systems, and human oversight of AI systems should be enabled.
    questions_and_answers:
      - question: |
          Explain the princple "Human, social and environmental wellbeing"
        answer: |
          This principle aims to clearly indicate from the outset that AI systems should be used for beneficial outcomes for individuals, society and the environment. AI system objectives should be clearly identified and justified. AI systems that help address areas of global concern should be encouraged, like the United Nation’s Sustainable Development Goals. Ideally, AI systems should be used to benefit all human beings, including future generations.
          AI systems designed for legitimate internal business purposes, like increasing efficiency, can have broader impacts on individual, social and environmental wellbeing. Those impacts, both positive and negative, should be accounted for throughout the AI system’s lifecycle, including impacts outside the organisation.
      - question: |
          Explain the princple "Contestability"
        answer: |
          This principle aims to ensure the provision of efficient, accessible mechanisms that allow people to challenge the use or output of an AI system, when that AI system significantly impacts a person, community, group or environment. The definition of the threshold for ‘significant impact’ will depend on the context, impact and application of the AI system in question.
          Knowing that redress for harm is possible, when things go wrong, is key to ensuring public trust in AI. Particular attention should be paid to vulnerable persons or groups.
          There should be sufficient access to the information available to the algorithm, and inferences drawn, to make contestability effective. In the case of decisions significantly affecting rights, there should be an effective system of oversight, which makes appropriate use of human judgment.
  - context: |
      The principles are entirely voluntary. They are designed to prompt organisations to consider the impact of using AI enabled systems. We intend them to be aspirational and complement, not substitute, existing AI regulations and practices.
      Not every principle will be relevant to your use of AI. 
      Not every business uses AI, and not every use of AI requires comprehensive analysis against the principles. For example, many businesses use systems that may incorporate AI such as email or accounting software. This use is unlikely to be of sufficient impact to require the use of the principles. 
      If your AI use doesn't involve or affect human beings, you may not need to consider all of the principles.
    questions_and_answers:
      - question: |
          When should I use Australia's AI principles?
        answer: |
          To help decide whether you should apply these ethical principles, consider the following threshold questions. If you answer 'yes' then applying the principles could help you plan for better outcomes. 
          Will the AI system you are developing or implementing be used to make decisions or in other ways have a significant impact (positive or negative) on people (including marginalised groups), the environment or society? 
          Are you unsure about how the AI system may impact your organisation or your customers/clients?
      - question: |
          Do I have to use Australia's AI principles?
        answer: |
          No, these principles are entirely voluntary.
  - context: |
      Australia's AI Ethics Principles are necessary to guide businesses and governments in responsibly designing, developing, and implementing artificial intelligence (AI) systems, ensuring they are safe, reliable, and fair, while minimizing potential negative impacts on individuals and society; these principles were written by the Department of Industry, Science and Resources. 
    questions_and_answers:
      - question: |
          Who wrote the Austalia's 8 AI Principles?
        answer: |
          Australia's 8 AI Ethics Principles were written by the Department of Industry, Science and Resources. 